import os
import base64
import cv2
import numpy as np
from PIL import Image
import io
import pandas as pd
import re

# Fix cho Pillow 10.0+ kh√¥ng c√≤n Image.ANTIALIAS
# EasyOCR v√† m·ªôt s·ªë th∆∞ vi·ªán v·∫´n c·∫ßn ANTIALIAS
if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

# Load drug database v√† PDF (cached)
_drug_db = None
_drug_db_path = None
_pdf_reader = None
_pdf_path = None
_ocr_reader = None  # EasyOCR reader (cache ƒë·ªÉ kh√¥ng load l·∫°i m·ªói l·∫ßn)

def get_drug_database():
    """Load v√† cache drug database"""
    global _drug_db, _drug_db_path
    
    # Get path relative to project root
    if _drug_db_path is None:
        # Try different possible paths - s·ª≠ d·ª•ng drug_database_refined.csv
        possible_paths = [
            os.path.join(os.path.dirname(__file__), '..', 'Crawldata', 'drug_database_refined.csv'),
            os.path.join(os.getcwd(), 'Crawldata', 'drug_database_refined.csv'),
            '/var/task/Crawldata/drug_database_refined.csv',  # Vercel lambda path
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                _drug_db_path = path
                break
    
    if _drug_db is None and _drug_db_path and os.path.exists(_drug_db_path):
        try:
            _drug_db = pd.read_csv(_drug_db_path)
            print(f"‚úÖ Loaded {len(_drug_db)} drugs from database")
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading database: {e}")
            _drug_db = pd.DataFrame()
    elif _drug_db is None:
        _drug_db = pd.DataFrame()
    
    return _drug_db

def get_pdf_reader():
    """Load v√† cache PDF reader"""
    global _pdf_reader, _pdf_path
    
    if _pdf_path is None:
        # Try different possible paths
        possible_paths = [
            os.path.join(os.path.dirname(__file__), '..', 'Crawldata', 'duoc-thu-quoc-gia-viet-nam-2018.pdf'),
            os.path.join(os.getcwd(), 'Crawldata', 'duoc-thu-quoc-gia-viet-nam-2018.pdf'),
            '/var/task/Crawldata/duoc-thu-quoc-gia-viet-nam-2018.pdf',  # Vercel lambda path
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                _pdf_path = path
                break
    
    if _pdf_reader is None and _pdf_path and os.path.exists(_pdf_path):
        try:
            from pypdf import PdfReader
            _pdf_reader = PdfReader(_pdf_path)
            print(f"‚úÖ Loaded PDF with {len(_pdf_reader.pages)} pages")
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading PDF: {e}")
            _pdf_reader = None
    elif _pdf_reader is None:
        _pdf_reader = None
    
    return _pdf_reader

def decode_base64_image(base64_string):
    """Decode base64 string th√†nh image"""
    try:
        # Remove data URL prefix if present
        if ',' in base64_string:
            base64_string = base64_string.split(',')[1]
        
        image_data = base64.b64decode(base64_string)
        image = Image.open(io.BytesIO(image_data))
        
        # Convert to RGB if necessary
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        return np.array(image)
    except Exception as e:
        print(f"Error decoding image: {e}")
        return None

def preprocess_image(image_array):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ c·∫£i thi·ªán OCR"""
    try:
        # Convert to grayscale
        if len(image_array.shape) == 3:
            gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = image_array
        
        # Apply denoising
        denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
        
        # Apply threshold
        _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Resize n·∫øu ·∫£nh qu√° nh·ªè (t·ªëi thi·ªÉu 300px width ƒë·ªÉ OCR t·ªët h∆°n)
        height, width = thresh.shape
        if width < 300:
            scale = 300 / width
            new_width = int(width * scale)
            new_height = int(height * scale)
            thresh = cv2.resize(thresh, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
        
        return thresh
    except Exception as e:
        print(f"Error preprocessing image: {e}")
        return image_array

def get_ocr_reader():
    """L·∫•y ho·∫∑c kh·ªüi t·∫°o EasyOCR reader (cache ƒë·ªÉ kh√¥ng load l·∫°i m·ªói l·∫ßn)"""
    global _ocr_reader
    if _ocr_reader is None:
        try:
            import easyocr
            print("üîÑ ƒêang kh·ªüi t·∫°o EasyOCR (l·∫ßn ƒë·∫ßu c√≥ th·ªÉ m·∫•t v√†i ph√∫t ƒë·ªÉ t·∫£i model)...")
            # H·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Anh
            _ocr_reader = easyocr.Reader(['vi', 'en'], gpu=False)
            print("‚úÖ EasyOCR ƒë√£ s·∫µn s√†ng!")
        except ImportError:
            print("‚ö†Ô∏è EasyOCR ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install easyocr")
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o EasyOCR: {e}")
            return None
    return _ocr_reader

def extract_text_from_image(image_array):
    """Tr√≠ch xu·∫•t text t·ª´ ·∫£nh s·ª≠ d·ª•ng EasyOCR"""
    try:
        reader = get_ocr_reader()
        if reader is None:
            # Fallback n·∫øu OCR kh√¥ng kh·∫£ d·ª•ng
            return None
        
        # EasyOCR c·∫ßn ·∫£nh ·ªü d·∫°ng numpy array (BGR ho·∫∑c RGB)
        # Chuy·ªÉn ƒë·ªïi t·ª´ grayscale sang RGB n·∫øu c·∫ßn
        if len(image_array.shape) == 2:
            # Grayscale -> RGB
            image_rgb = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)
        else:
            image_rgb = image_array
        
        # Chuy·ªÉn t·ª´ RGB sang BGR (OpenCV format)
        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # OCR v·ªõi EasyOCR
        results = reader.readtext(image_bgr)
        
        if not results:
            return None
        
        # L·∫•y t·∫•t c·∫£ text ƒë√£ nh·∫≠n di·ªán, ∆∞u ti√™n text c√≥ confidence cao
        texts = []
        for (bbox, text, confidence) in results:
            if confidence > 0.3:  # Ch·ªâ l·∫•y text c√≥ ƒë·ªô tin c·∫≠y > 30%
                texts.append(text)
        
        if not texts:
            return None
        
        # K·∫øt h·ª£p t·∫•t c·∫£ text th√†nh m·ªôt chu·ªói
        # ∆Øu ti√™n text d√†i nh·∫•t (th∆∞·ªùng l√† t√™n thu·ªëc)
        combined_text = ' '.join(texts)
        
        # T√¨m text d√†i nh·∫•t (c√≥ th·ªÉ l√† t√™n thu·ªëc)
        longest_text = max(texts, key=len) if texts else combined_text
        
        # Tr·∫£ v·ªÅ text d√†i nh·∫•t ho·∫∑c k·∫øt h·ª£p t·∫•t c·∫£
        return longest_text if len(longest_text) > 10 else combined_text
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói OCR: {e}")
        return None

def search_drug_in_database(drug_name):
    """T√¨m ki·∫øm thu·ªëc trong database"""
    drug_db = get_drug_database()
    
    if drug_db is None or drug_db.empty:
        return None
    
    # T√¨m ki·∫øm kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng
    drug_name_lower = drug_name.lower().strip()
    
    # T√¨m exact match
    exact_match = drug_db[drug_db['DrugName'].str.lower() == drug_name_lower]
    if not exact_match.empty:
        return exact_match.iloc[0].to_dict()
    
    # T√¨m partial match
    partial_match = drug_db[drug_db['DrugName'].str.lower().str.contains(drug_name_lower, na=False)]
    if not partial_match.empty:
        return partial_match.iloc[0].to_dict()
    
    # T√¨m theo t·ª´ kh√≥a
    keywords = drug_name_lower.split()
    for keyword in keywords:
        if len(keyword) > 3:  # Ch·ªâ t√¨m t·ª´ c√≥ > 3 k√Ω t·ª±
            keyword_match = drug_db[drug_db['DrugName'].str.lower().str.contains(keyword, na=False)]
            if not keyword_match.empty:
                return keyword_match.iloc[0].to_dict()
    
    return None

def extract_drug_details_from_pdf(page_number, offset=-1):
    """
    Tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt t·ª´ PDF d·ª±a tr√™n s·ªë trang
    T√¨m th√†nh ph·∫ßn, c√¥ng d·ª•ng, ch·ªâ ƒë·ªãnh, ch·ªëng ch·ªâ ƒë·ªãnh...
    """
    pdf_reader = get_pdf_reader()
    
    if pdf_reader is None:
        return {}
    
    try:
        # Chuy·ªÉn ƒë·ªïi s·ªë trang s√°ch th√†nh index PDF (pypdf ƒë√°nh s·ªë t·ª´ 0)
        pdf_page_index = int(page_number) + offset - 1
        
        # ƒê·∫£m b·∫£o index h·ª£p l·ªá
        if pdf_page_index < 0 or pdf_page_index >= len(pdf_reader.pages):
            # Th·ª≠ kh√¥ng c√≥ offset
            pdf_page_index = int(page_number) - 1
            if pdf_page_index < 0 or pdf_page_index >= len(pdf_reader.pages):
                return {}
        
        # ƒê·ªçc trang PDF
        page = pdf_reader.pages[pdf_page_index]
        text = page.extract_text()
        
        if not text:
            return {}
        
        details = {
            'composition': '',
            'indications': '',
            'contraindications': '',
            'dosage': '',
            'full_text': text[:2000]  # Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh qu√° d√†i
        }
        
        # Regex patterns ƒë·ªÉ t√¨m c√°c th√¥ng tin
        patterns = {
            'composition': re.compile(r'(Th√†nh ph·∫ßn|Th√†nh ph·∫ßn ch√≠nh|Ho·∫°t ch·∫•t)[:\.]\s*(.+?)(?:\n|$)', re.IGNORECASE),
            'indications': re.compile(r'(Ch·ªâ ƒë·ªãnh|C√¥ng d·ª•ng|T√°c d·ª•ng)[:\.]\s*(.+?)(?:\n|Ch·ªëng ch·ªâ ƒë·ªãnh|Li·ªÅu d√πng|$)', re.IGNORECASE | re.DOTALL),
            'contraindications': re.compile(r'(Ch·ªëng ch·ªâ ƒë·ªãnh|Kh√¥ng d√πng)[:\.]\s*(.+?)(?:\n|Li·ªÅu d√πng|C√°ch d√πng|$)', re.IGNORECASE | re.DOTALL),
            'dosage': re.compile(r'(Li·ªÅu d√πng|C√°ch d√πng|Li·ªÅu l∆∞·ª£ng)[:\.]\s*(.+?)(?:\n|T√°c d·ª•ng ph·ª•|$)', re.IGNORECASE | re.DOTALL)
        }
        
        # T√¨m t·ª´ng lo·∫°i th√¥ng tin
        for key, pattern in patterns.items():
            match = pattern.search(text)
            if match:
                details[key] = match.group(2).strip()[:500]  # Gi·ªõi h·∫°n ƒë·ªô d√†i
        
        return details
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc PDF trang {page_number}: {e}")
        return {}

